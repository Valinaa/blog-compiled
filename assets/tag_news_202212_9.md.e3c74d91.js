import{_ as t,o as e,c as E,O as a}from"./chunks/framework.7d066bc9.js";const r="/assets/W020221206496455575703.564a560f.jpg",o="/assets/W020221206496561972647.1e24342e.jpg",n="/assets/W020221206496710337466.5e9aef1b.jpg",m=JSON.parse('{"title":"心理所开发出Think-Aloud fMRI研究范式并刻画静息态自发思维的大脑表征模式","description":"","frontmatter":{"title":"心理所开发出Think-Aloud fMRI研究范式并刻画静息态自发思维的大脑表征模式","hidden":false,"tag":["心理学","其他","其他"],"sticky":100,"top":1},"headers":[],"relativePath":"tag_news/202212_9.md","filePath":"tag_news/202212_9.md","lastUpdated":null}'),s={name:"tag_news/202212_9.md"},A=a('<h2 id="心理所开发出think-aloud-fmri研究范式并刻画静息态自发思维的大脑表征模式" tabindex="-1">心理所开发出Think-Aloud fMRI研究范式并刻画静息态自发思维的大脑表征模式 <a class="header-anchor" href="#心理所开发出think-aloud-fmri研究范式并刻画静息态自发思维的大脑表征模式" aria-label="Permalink to &quot;心理所开发出Think-Aloud fMRI研究范式并刻画静息态自发思维的大脑表征模式&quot;">​</a></h2><blockquote><p><strong>标签:</strong> [心理学] [其他] [其他]<br><strong>高频词:</strong> 静息, 研究, 思维, , 大脑</p></blockquote><p>静息态功能磁共振成像（Resting-State fMRI）因设计简单、便于积累大数据、临床易实施等优势而成为主流脑影像研究手段。采用静息态方法的研究取得了丰硕成果，但静息态fMRI的可靠性常受到质疑。在导致可靠性降低的诸多因素中，静息态下无约束的心理活动变异可能起到关键作用。</p><p>“静息态”磁共振数据完全来自“静止”的大脑？已有研究表明，虽然静息态扫描过程不涉及外部驱动的认知加工，但个体在该过程中仍会有意识地产生许多持续的内源性的认知加工（自发思维）。尽管构成个体休息期间持续体验的认知、感知和运动过程丰富多样，但研究较少承认这些贡献，而是使用单一的术语如“内在”（intrinsic）或“自发”（spontaneous）来描述在静息态fMRI期间观察到的所有神经活动。然而，将这部分内源性持续的认知加工所引发的脑活动简单地归为人脑的内在活动不利于静息态脑成像研究的发展。对于群体间比较研究，如果组间存在自发思维倾向差异，那么他们的静息态自发思维可能存在组间系统差异，进而体现在静息态的神经活动模式上。较多类型的精神疾病均与自发思维的异常有联系，例如，抑郁症患者自发思维出现的频率显著高于正常个体。他们的自发思维内容多是负性的、指向过去的。因此，对于常见的精神疾病与健康人的对比研究，静息态自发思维的系统差异会影响静息态方法的效度。</p><p>中国科学院心理研究所行为科学重点实验室严超赣研究组开发了出声思维功能磁共振成像（Think-Aloud fMRI）新范式，采用出声思维法收集了101名被试在磁共振中实时的思维流（质控后最终分析样本为86人）。与经典的静息态fMRI不同的是，被试睁眼注视屏幕上的“+”注视点之外，当发现脑中出现想法/画面时需要当即汇报出来。研究检测了think-aloud fMRI探究持续思维流的可行性，包括阐明自发言语报告时大脑的激活模式以及思想内容是否与大脑活动相关。研究融合自然语言处理（natural language processing，NLP），使用表征相似性分析 （Representational similarity analysis，RSA）刻画了静息态下思维流的大脑表征模式（图1），即将录音转录为文本，并按照时间性和话题相似性对思维内容转换进行标注和切分，进一步使用NLP将每个思维片段量化为768维固定长度的向量，以构建语义特征表征差异性矩阵（representational dissimilarity matrix，RDM）。研究计算每个思维片段对应的平均BOLD（blood oxygenation level-dependent）值以构建神经水平的RDM。研究使用RSA在三个全脑神经水平上探索了静息态思维流的大脑表征模式——体素水平（全脑探照灯分析）、区域水平（采用Schaefer 400 分区）和系统水平（采用七个Yeo网络）。</p><p>全脑三个水平的RSA分析结果均表明，静息态下思维流的大脑表征模式涉及广泛的大脑区域，不仅涉及默认网络（default mode network，DMN），而且涉及所有七个大脑网络（图2、3）。通过直接将思维的自发性和动态性与大脑活动的自发性和动态性相结合，研究实证地获得了大脑静息态下自发活动的内在空间模式。</p><p>该研究强调了关注静息态下持续认知活动的重要性，阐明了大脑静息态思维流的内在空间模式，并为时空神经科学提供了支持，将推进脑自发活动研究和静息态fMRI研究。在方法上，该研究证明了将出声思维、自然语言处理、表征相似性分析与fMRI结合起来以探讨静息态思维流与大脑自发活动之间联系的潜力，展望了Think-Aloud fMRI研究范式的研究前景。未来，严超赣研究组将进一步明确静息态下不同思维内容特征的大脑空间模式。</p><p>相关研究成果在线发表在<em>NeuroImage</em>上。研究代码已开源共享在<a href="https://github.com/Chaogan-Yan/PaperScripts/tree/master/LiHX%5C_2022%5C_NeuroImage%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%B7%B2%E5%85%B1%E4%BA%AB%E5%9C%A8http://rfmri.org/ThinkAloudfMRIData%EF%BC%8C%E5%B9%B6%E5%B0%86%E5%9C%A8%E5%BF%83%E7%90%86%E7%A7%91%E5%AD%A6%E6%95%B0%E6%8D%AE%E9%93%B6%E8%A1%8C%E6%9B%B4%E6%96%B0%E3%80%82%E7%A0%94%E7%A9%B6%E5%B7%A5%E4%BD%9C%E5%BE%97%E5%88%B0%E7%A7%91%E6%8A%80%E5%88%9B%E6%96%B02030-%E8%84%91%E7%A7%91%E5%AD%A6%E4%B8%8E%E7%B1%BB%E8%84%91%E7%A0%94%E7%A9%B6%E9%87%8D%E5%A4%A7%E9%A1%B9%E7%9B%AE%E3%80%81%E5%9B%BD%E5%AE%B6%E9%87%8D%E7%82%B9%E7%A0%94%E5%8F%91%E8%AE%A1%E5%88%92%E3%80%81%E5%9B%BD%E5%AE%B6%E8%87%AA%E7%84%B6%E7%A7%91%E5%AD%A6%E5%9F%BA%E9%87%91%E3%80%81%E4%B8%AD%E7%A7%91%E9%99%A2%E3%80%81%E5%8C%97%E4%BA%AC%E5%B8%82%E7%A7%91%E6%8A%80%E6%96%B0%E6%98%9F%E8%AE%A1%E5%88%92%E5%8F%8A%E5%BF%83%E7%90%86%E6%89%80%E7%A7%91%E5%AD%A6%E5%9F%BA%E9%87%91%E7%9A%84%E6%94%AF%E6%8C%81%E3%80%82" target="_blank" rel="noreferrer">https://github.com/Chaogan-Yan/PaperScripts/tree/master/LiHX\\_2022\\_NeuroImage，数据已共享在http://rfmri.org/ThinkAloudfMRIData，并将在心理科学数据银行更新。研究工作得到科技创新2030-脑科学与类脑研究重大项目、国家重点研发计划、国家自然科学基金、中科院、北京市科技新星计划及心理所科学基金的支持。</a></p><p><a href="https://doi.org/10.1016/j.neuroimage.2022.119775" target="_blank" rel="noreferrer">论文链接</a></p><p><img src="'+r+'" alt=""></p><p>图1.实验分析示意图</p><p><img src="'+o+'" alt=""></p><p>图2.体素水平的RSA分析结果</p><p><img src="'+n+'" alt=""></p><p>图3.区域水平的RSA分析结果</p>',15),i=[A];function p(l,B,_,d,c,f){return e(),E("div",null,i)}const g=t(s,[["render",p]]);export{m as __pageData,g as default};
