import{_ as t,o as e,c as s,O as p}from"./chunks/framework.7d066bc9.js";const a="/assets/W020230214401043902584.361b3919.png",n="/assets/W020230214401128360329.f653a039.png",o="/assets/W020230214401211579947.e336a3b2.png",r="/assets/W020230214401284947228.99ed4cd8.png",_="/assets/W020230214401365838896.56e796e2.png",i="/assets/W020230214401442093554.bc769aab.png",c="/assets/W020230214496532042068.038736ac.png",S=JSON.parse('{"title":"科学家提出注意力脉冲神经网络","description":"","frontmatter":{"title":"科学家提出注意力脉冲神经网络","hidden":false,"tag":["生物学","信息与系统科学","其他"],"sticky":100,"top":1},"headers":[],"relativePath":"tag_news/202302_102.md","filePath":"tag_news/202302_102.md","lastUpdated":null}'),m={name:"tag_news/202302_102.md"},l=p('<h2 id="科学家提出注意力脉冲神经网络" tabindex="-1">科学家提出注意力脉冲神经网络 <a class="header-anchor" href="#科学家提出注意力脉冲神经网络" aria-label="Permalink to &quot;科学家提出注意力脉冲神经网络&quot;">​</a></h2><blockquote><p><strong>标签:</strong> [生物学] [信息与系统科学] [其他]<br><strong>高频词:</strong> 脉冲, , 注意力, 神经网络,</p></blockquote><p>近日，中国科学院自动化所脑图谱与类脑智能实验室研究员李国齐与西安交通大学教授赵广社合作，在<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>（<em>TPAMI</em>）上，发表了题为<em>Attention Spiking Neural Networks</em>的研究论文。该工作将注意力机制融入百万级规模脉冲神经网络，在ImageNet-1K数据集上首次取得了与传统人工神经网络相当的性能，且理论能效为同等结构人工神经网络的31.8倍。这一方法在显著提升任务性能的同时能够大幅降低网络能量消耗，为低功耗神经形态系统的发展提供了新思路。</p><p>近年来，以传统人工神经网络为代表的深度学习在一些任务上展现出接近或超越人类的能力。在取得这些成就的同时，人类付出了海量的能耗代价。而人脑能够以极低地能耗高效完成相同或更复杂的任务。如何使得机器智能像人脑一样高效工作是科学家孜孜以求的目标。基于脉冲神经网络的神经形态计算提供了极具吸引力的传统人工智能的低能耗替代方案。脉冲神经元模拟了生物神经元中的复杂时空动态，其表达能力在理论上强于现有的人工神经元。同时，脉冲神经元继承了生物神经元中的脉冲通信方式，这是脉冲神经网络实现低功耗的关键。一方面，在神经形态系统中只需要执行低能耗的突触加法；另一方面，事件驱动特性使得只有脉冲神经元发放脉冲时神经形态系统才会触发计算。因此，如何以低脉冲发放率实现高任务性能是神经形态计算中的重要问题。人脑可以自然而有效地在复杂场景中找到重要信息，被称为注意力机制。注意力机制被广泛应用于深度学习，并取得显著效果。然而，在神经形态计算领域的应用仍颇具挑战性。</p><p>为了将注意力机制融入脉冲神经网络，需要考虑三个基础问题。一是脉冲神经网络高能效的关键是以脉冲通信为基础的事件驱动特性，注意力机制不能破坏这种特性。二是脉冲神经网络应用场景广泛，需要有多样性的设计以保证其在各种场景中的有效性。三是二进制脉冲通信使深度脉冲神经网络易出现由梯度消失或爆炸带来的性能退化问题，注意力机制的加入至少不应加剧退化问题。</p><p>如图1所示，人脑中注意力的功能实现主要体现在对不同脑区或神经元脉冲发放的调节。受此启发，该研究通过注意力机制来优化脉冲神经网络内部的膜电势分布，关注重要特征并抑制不必要的特征，进而起到调节脉冲发放的作用。网络架构如图2所示。进一步，为了使注意力脉冲神经网络适应于各种应用场景，如图3所示，该研究融合了时间、通道和空间三个维度，以学习“何时”“什么”“哪里”是重要的。</p><p>科研团队在基于事件的动作识别数据集以及静态图像分类数据集ImageNet-1K上对提出的多维度注意力脉冲神经网络进行实验。实验表明，注意力模块的加入帮助脉冲神经网络在性能上有显著提升，网络中的脉冲数量也能降低，从而降低模型能耗。在DVS128 Gait数据集上，多维度注意力模块能够使原始脉冲神经网络降低81.6%的脉冲发放，同时带来4.7%的性能提升（表1）。在ImageNet-1K数据集上，注意力脉冲神经网络首次取得了与传统人工神经网络相当的性能，且理论能效为同等结构人工神经网络的31.8倍（表2）。</p><p>该研究还提出了新的可视化方法用来分析为何所提出的注意力模块能够在降低脉冲发放的同时提升网络性能。如图4、图5所示，加入了注意力机制的脉冲神经网络在专注重要信息的同时，能够抑制不重要的背景噪声信息（特征图中的每个像素点代表一个神经元发放率。颜色越红代表发放率越大；越蓝代表发放率越小）。而在所有的特征图中，噪声特征图或神经元中的脉冲发放率均较高。因此，抑制噪声信息能够显著降低网络中的脉冲发放。</p><p>进一步，该研究通过块动态等距理论证明将所提出的注意力模块加入到深度脉冲神经网络中仍能实现动态等距。也就是说，注意力模块在深度脉冲神经网络中不会引起性能退化。</p><p>综上，本工作探索了如何在脉冲神经网络中使用注意力机制，发现了通过将注意力机制作为辅助模块插入到脉冲神经网络中能够在大幅降低网络脉冲发放的同时显著提升任务性能。通过可视化原始和注意力脉冲神经网络的脉冲响应可知，注意力机制可帮助原始网络在专注重要信息的同时抑制噪声信息，而噪声通道或神经元中包含大量的脉冲。因此，在基于脉冲神经网络的神经形态计算中，能够实现像人脑一样以更低的能耗获得更好的性能。</p><p>研究工作得到北京市杰出青年科学基金、国家自然科学基金重点项目和联合基金项目区域创新发展联合基金等的支持。北京大学、清华大学的科研人员参与研究。</p><p><a href="https://ieeexplore.ieee.org/document/10032591" target="_blank" rel="noreferrer">论文链接</a></p><p><img src="'+a+'" alt=""></p><p>图1.大脑在多层级结构上存在注意力机制</p><p><img src="'+n+'" alt=""></p><p>图2.多维度注意力脉冲神经网络，注意力机制被用来调节膜电势分布</p><p><img src="'+o+'" alt=""></p><p>图3.时间、通道、空间维度注意力机制示意图</p><p>表1.在DVS128 Gesture/Gait上结果性能对比</p><p><img src="'+r+'" alt=""></p><p>表2.在ImageNet-1K上结果性能对比</p><p><img src="'+_+'" alt=""></p><p><img src="'+i+'" alt=""></p><p>图4.Gait数据集中的案例分析</p><p><img src="'+c+'" alt=""></p><p>图5.DVS128 Gait数据集中的脉冲响应；注意力机制能够显著抑制背景噪声。</p>',26),g=[l];function d(h,f,u,b,k,I){return e(),s("div",null,g)}const T=t(m,[["render",d]]);export{S as __pageData,T as default};
